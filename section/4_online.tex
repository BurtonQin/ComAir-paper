\section{Production-Run Algorithmic Profiling}
\label{sec:online}

In this section, we discuss our design and 
implementation for production-run algorithmic profiling. 
For production-run usage, profiles are collected from user side.
It is very important to keep a low runtime overhead, since
end users cannot tolerate any observable performance overhead. 

To achieve the requirement of production-run usage,
our design follows several principles. 

First, \textit{taxonomy-guided}. 
Different from the generic metric (or technique) used in in-house profiling,
we design our online technique 
under the guidance of the taxonomy in Section~\ref{sec:study}.
We focus on the majority of complexity problems, 
caused either by repeated execution of loops ($N^k$)
or recursive functions ($2^N$).  

Second, \textit{focused checking}.
Developers could choose a suspicious loop or recursive function to monitor
In order to better understand their complexity in production runs.
Our tool could also be used with performance diagnosis tools~\cite{SongOOPSLA2014} 
or traditional profilers,
and focus on loops or recursive functions leading 
to user-perceived performance problems.

Third, \textit{approximation}. 
We design lightweight metrics to estimate heavyweight metrics.
We also apply sampling and infer information for the whole 
execution based on collected samples.


\subsection{Approximately profiling recursions}

Given a static recursive function \textit{F},
when \textit{F} is called, 
a dynamic instance \textit{A} is created.
\textit{A} can create a new instance, \textit{B}, and increase 
the length of the recursive call chain from 1 to 2 by calling \textit{F}.
\textit{B} can also create a new instance, \textit{C}.
In this case, we consider that \textit{A} creates \textit{C} indirectly.
Both \textit{B} and \textit{C} are descendants of 
\textit{A} in the dynamic call tree. 

To efficiently profile a recursive instance \textit{A}, 
we make two estimations.


First, we use the number of instances created by \textit{A} directly or indirectly 
to estimate execution \textit{cost} of \textit{A}.
By doing this, we assume that \textit{cost} 
will be roughly the same for an instance after excluding 
\textit{cost} spent in its descendants.

Second, we use the length of 
the maximum recursive call chain starting from \textit{A} to estimate
the input \textit{size} of \textit{A}. 
The intuition is that 
when an instance is created by \textit{A} directly or indirectly, 
a distinct input will be processed by \textit{A}.
The maximum length of the recursive call chain starting from \textit{A} 
is the number of distinct inputs processed by \textit{A} simultaneously.
Therefore, we could use the length of the recursive call chain 
to estimate the input \textit{size}. 
For example, 
the maximum length of the recursive call chain from an instance of \texttt{fib} 
in Figure~\ref{fig:fib} is $n-1$, 
by always calling \texttt{fib(n-1)} recursively on line 3.
The maximum length for an instance of \texttt{mult\_alg} 
in Figure~\ref{fig:gcc27733} 
is roughly equal to the number of 1s in the binary form of \texttt{t},
since the bitwise operations always remove one 1 in the binary 
form before making the recursive function call.  
  

To implement this, 
we instrument two global counters, 
\texttt{instance\_count} and \texttt{callchain\_length} 
to maintain the number of created instances and 
the length of recursive call chain, respectively. 
At the entry point of a monitored recursive function,
we will increment \texttt{instance\_count} and \texttt{callchain\_length} by 1
and dump their values to log.
Before the exit of the monitored recursive function,
we will dump the values of 
\texttt{instance\_count} and \texttt{callchain\_length} 
to log
and decrement \texttt{callchain\_length} by 1.
Generated logs will be processed when the monitored program finish execution, 
and \textit{input} and \textit{cost} 
will be calculated for each recursive instance.  

Sometimes, when recursive instances are too many, 
only recording two counter values will still generate a large log, 
incurring large runtime and memory overhead. 
We propose to use sampling to decide when to dump counter values to log.
When we decide to sample an instance, 
we will record counter values for the instance and all its descendants. 


\subsection{Approximately profiling loops}

As we discussed in Section~\ref{sec:study}, 
all complexity problems in polynomial complexity 
are caused by repeated executions of a buggy loop.
Previous works show that sampling code constructs 
executing multiple 
times can lower runtime overhead, 
while can still collect enough runtime information~\cite{SongOOPSLA2014,ldoctor}. 
Inspired by our study and the previous works, 
we apply sampling to efficiently profile loops with multiple executions. 
 

As we discussed in Section~\ref{sec:inhouse}, 
to infer the complexity function, 
we need select metrics for \textit{cost} and input \textit{size}.

{\underline{\textit{Cost Metric.}}
To efficiently profile a loop, we use the total loop iteration number 
to estimate the total \textit{cost} of all executions.
We initialize a local counter to be 0 at the beginning of the program.
We increase the counter by 1 in the loop header of the monitored loop.
We dump the counter value to log before the program exits. 
Compared with using executed BBs discussed in Section~\ref{sec:inhouse}, 
collecting loop iteration number will incur a smaller overhead.   


{\underline{\textit{Input Size Metric.}}
We still use RMS as input \textit{size} metric for a monitored loop, 
but we will infer RMS from sampled information, 
which is different from what we did in Section~\ref{sec:inhouse}.
The algorithm discussed in Section~\ref{sec:inhouse} 
focuses on memory reads conducted by a single execution 
independently from other executions 
of the same code construct. 
For example, one single execution of 
the buggy loop of MySQL\#27287 (Figure~\ref{fig:mysql27287})
is always linear, as shown in Figure~\ref{fig:mysql27287-in}.
After merging information of different executions from the outer loop,
we can observe the polynomial complexity 
in Figure~\ref{fig:mysql27287-out}.

To estimate RMS for all executions of a monitored loop, 
we first sample memory read and write information 
from several loop executions. 
We then merge sampled information and 
infer RMS for all executions. 

How to sample memory access information is similar to previous 
statistical debugging works~\cite{liblit03,liblit05,CCI,SongOOPSLA2014,ldoctor}.
We make a cloned version of the monitored loop.
We instrument the cloned version to trace memory accesses.
We consider memory accesses conducted by the loop directly
and indirectly. 
Before each execution of the monitored loop, 
we randomly decide whether the instrumented version 
or the original version will execute. 
How many times the instrumented version is executed 
depends on a configurable sampling rate. 
We also add extra marks into the trace to 
differ information sampled from different loop instances. 
We use an off-line analysis to figure out which 
memory addresses are read firstly by a sampled loop instance. 


We apply mark-and-recapture method~\citep{mark-recapture} to estimate RMS. 
Mark-and-recapture is a commonly used statistical method 
to estimate the size of animal population. 
By using this method, a portion of animals is captured, marked, and released. 
Then, another portion is captured.
The size of the whole animal population is estimated 
based on the ratio of marked animals in the second captured portion.  

Since mark-and-recapture needs to compare two captured portions, 
we config our sampling policy to always sample 
two consecutive loop execution instances. 
Assume we have a pair of sampled instances with RMS 
as $N_1$ and $N_2$ respectively.  
If $M$ memory cells read firstly by both of the two loop instances, 
we estimate the RMS for all loop instances as $N=N_1*N_2/M$. 
{\bf xxx I am pretty sure that the current implementation is wrong}













\subsection{Discussions}

