\section{In-house Algorithmic Profiling}
\label{sec:inhouse}

In this section, we discuss the design and implementation for in-house algorithmic profiling.
Under in-house setting, 
developers can conduct algorithmic profiling 
to detect previously unknown complexity problems before releasing their software, 
or developers could diagnose and fix complexity problems 
reported by users through bug databases.
%For both of these two cases, 
%run-time overhead is not a major concern. 


\subsection{Design}
To conduct algorithmic profiling~\cite{Aprof1,Aprof2,AlgoProf},
we first need to record input \textit{size} and \textit{cost} for different code constructs 
during multiple executions,
we then plot records from the same code construct with input size as x-axis and cost as y-axis, 
and finally, we infer a cost function of the input size by using 
statistical curve fitting~\cite{curve-fitting} 
or curving bounding~\cite{curve-bounding}. 
Code constructs could be loops~\cite{AlgoProf} and functions~\cite{Aprof1,Aprof2}. 
The fundamental design points for algorithmic 
profiling are to select suitable metrics for input size and cost. 

\begin{figure*}
\centering
\subfloat[MySQL\#27287]{\includegraphics[width=0.24\linewidth]{figure/apache34464-line}\label{fig:mysql27287-line}} 
\subfloat[GCC\#27733]{\includegraphics[width=0.24\linewidth]{figure/apache34464-line}\label{fig:jaccard}}
\subfloat[GCC\#27733]{\includegraphics[width=0.24\linewidth]{figure/apache34464-line}\label{fig:jaccard}}
\subfloat[Apache\#34464]{\includegraphics[width=0.24\linewidth]{figure/apache34464-line}\label{fig:apache34464-line}} \\ 
\vspace{-0.1in}
\caption{Cost function using RMS as input size. XXXXXX} 
\label{fig:heat} 
\end{figure*} 


%{{\bf{\underline{\textit{Input designs.}}}}
\subsubsection{How to design input metric?}
Many metrics can be used to measure input for a code construct. 
We discuss commonly used ones as follows.

\underline{\textit{Program input.}}
As discussed in Section~\ref{sec:process}, 
users tend to specify how to change the whole program 
input in order to describe the perceived complexity problem.
It is fairly easy to measure input size for the whole program based on users' report.
One way to measure input size for a code construct inside a program
is to simply use the input size of the whole program. 

\underline{\textit{Read memory size.}}
Read memory size (RMS) is proposed as input size metric~\cite{Aprof1,Aprof2} . 
RMS is defined as the number of distinct memory cells 
whose first access is read. 
RMS consider both read conducted by a code construct directly 
and read conducted by 
functions called from the code construct. 

RMS is a generic metric for input size 
and it can provide important input information for many complexity problems.   
For example, 
RMS for one execution of
the buggy loop in Figure~\ref{fig:mysql27287}
is roughly equal to 2 times the number of \texttt{XML\_NODE} 
accessed during the execution, 
because \texttt{level} field and \texttt{type} field of 
different \texttt{XML\_NODE}s are read in different loop iteration.
Although variable \texttt{p} and \texttt{level} are also read in each iteration,
RMS only considers distinct memory cells and 
only increments its value for the first read on these two variables in the first iteration. 
There is also an outer loop, 
and the outer loop invokes \texttt{xml\_parent\_tag} 
for every \texttt{XML\_NODE} contained
in the same array \texttt{items}. 
For that outer loop, its RMS is in linear relationship 
with the size of array \texttt{items}, 
since RMS only considers distinct memory cells 
and multiple read conducted on the same memory 
cell of array \texttt{items} will not increment RMS value. 
The cost function containing the outer loop is shown 
in Figure~\ref{fig:mysql27287-line}.

{\underline{\textit{Data structure size.}}}
The number of accessed elements of a data 
structure could also be used to measure 
input size for a code construct~\cite{AlgoProf}. 
Commonly used data structures include linked list and arrays.
Using data structure size can provide more semantic information for 
analyzed code construct.
For example, if we focus on array \texttt{items}, 
the input size for both 
inner loop and outer loop of MySQL\#27287 is 
the number of accessed elements of array \texttt{items}.
Developers can clearly see that complexity of each execution 
of the inner loop is in linear relationship with accessed elements, 
while the complexity of outer loop is in $O(N^2)$ relationship. 

In the reminder of this paper, we will focus on RMS as input metric. 
We skip the whole program input, 
because it is related to the input of a code construct in various ways.
Changing the whole program input may not change input sizes for 
all code constructs. 
Using the input size of the whole program as input metric for a code construct
construct may lead to incorrect profiling results. 
We also skip data structure size,
because it is not a generic measure. 
We need to design and implement extra static and dynamic techniques 
to identify data structures and figure out their sizes.

\subsubsection{How to design cost metric?}
There are also a lot of metrics which can be used to measure execution cost, 
such as the number of executed instructions, 
the time elapsed during execution,
the number of executed basic blocks (BBs), 
loop iteration, 
and the number of recursive function call instances.

During our in-house technique design, 
we focus on the number of executed BBs. 
We do not use execution time, 
because when a code construct takes very little time,
execution time may not provide an accurate measurement. 
We do not use the number of executed instructions, 
because this number is highly correlated with the number of BBs. 
Loop iteration and the number of recursive call instances are estimates 
for the number of BBs. 
We do not use these two when designing in-house algorithmic profiling, 
but we will leverage them when building production-run techniques.  

\subsection{Implementation optimizations}

Aprof~\cite{Aprof1, Aprof2} is an algorithmic profiling tool built on Valgrind. 
Aprof uses RMS as input metric and executed BBs as cost metric.
Complexity information will be attributed to functions after profiling. 
We use LLVM framework to build an in-house algorithmic profiling tool.
Our tool building starts from the instrumentation algorithms used in aprof. 
We design a set of optimizations to reduce the runtime overhead, 
while providing accurate results.
In this section, we will first overview instrumentation algorithms in aprof firstly, 
and we will then discuss our designed optimizations. 

\subsubsection{Background}
To count executed BBs and RMS for each function call instance,
aprof runtime needs to maintain 5 global variables:
\texttt{cost}, 
tracking how many basic blocks are executed since the monitored program starts running, 
\texttt{count}, 
serving as the current timestamp and incremented by 1 after each function invocation, 
\texttt{ts}, 
a hash table containing latest access timestamp for each memory cell,
\texttt{S}, 
a shadow stack tracking all active functions, 
and \texttt{top}, 
tracking the top of \texttt{S}.

Aprof instruments hook functions for 4 types of instructions: 
\texttt{call}, \texttt{return}, \texttt{read}, and \texttt{write}. 
When a function is invoked, 
\texttt{call} hook function will increment timestamp variable \texttt{count}
and grow the shadow stack \texttt{S} by incrementing \texttt{top}.
When a function returns,
\texttt{return} hook function will 
generate a log 
containing the returning function's RMS and executed BBs.
Since RMS also considers memory read conducted by 
invoked callee functions, 
\texttt{return} hook function will add 
the RMS of the returning function to its caller on the stack. 
\texttt{read} hook function needs to query the hash table \texttt{ts} to decide  
whether to increment RMS for the function on top of the shadow stack \texttt{S}.
Both \texttt{read} and \texttt{write} 
hook function will update hash table \texttt{ts}
to maintain the latest access timestamp for each memory cell. 




%{{{\bf{\underline{\textit{Aprof overview.}}}}
%\subsubsection{Background}
%Aprof uses the number of executed basic blocks as cost metric.
%To measure this number, aprof keeps a global counter \texttt{cost}, 
%which tracks how many basic blocks are executed since 
%starting the monitored program.
%To figure out whether a memory cell is accessed by the same function invocation before,
%aprof keeps another global counter \texttt{count}, 
%which tracks how many functions have been invoked.  
%Aprof maintains a shallow stack \texttt{S}, 
%which grows as the monitored program makes a function invocation, 
%and shrinks as the monitored program returns. 
%Aprof uses the third global variable \\texttt{top} to track the top of \texttt{S}.
%Aprof also maintains a hashmap \texttt{ts}, 
%which tracks latest access function for each distinct memory cell. 

%Aprof instruments 4 types of instructions: \texttt{call}, 
%\texttt{return}, \texttt{read}, and \texttt{write}. 
%When the monitored program makes a function call,
%aprof will increase \texttt{count} and \texttt{top} by 1.
%The new added stack entry will be initialized as follows, 
%\texttt{top.ts=count}, 
%\texttt{top.rms=0} and \texttt{top.cost=cost}.  
%Where the monitored program returns,
%aprof will create a log based on the content inside \texttt{S[top]}
%contribute the rms 
%of the returned function to its caller by doing \texttt{S[top-1].rms+=S[top].rms},
%and shrink the stack. 
%For a memory read on a cell \texttt{w},
%if \texttt{w}'s last access timestamp \texttt{ts[w]} is smaller 
%than the timestamp when the current function is invoked \texttt{S[top].ts},
%aprof will increase the RMS value for the current function.
%Since aprof will contribute an invoked function's rms to its caller, 
%aprof will also check active functions on the shadow stack and 
%decrease their RMS when necessary..   
%Aprof will set memory cell \texttt{w}'s latest access time 
%for all memory \texttt{read} and \texttt{write} on \texttt{w}.
%{\bf xxxx: these two parameters are very bad}
%{\bf remember to discuss how to change function to loop}

\subsubsection{Optimizations}
We design several optimizations to reduce the 
runtime overhead for our LLVM implementation. 

Our first optimization is designed to efficiently count the number of executed basic blocks.
Instead of incrementing a global counter \texttt{cost} inside every basic block, 
we apply an algorithm to decide where to update \texttt{cost} and how to update \texttt{cost}  
The algorithm was designed to efficiently count program events through selectively instrumenting counter 
on edges of control flow graph~\cite{xx}. 
It has already been effectively applied for path profiling~\cite{xx}.

To apply the algorithm, we first instrument a local counter 
\texttt{local\_cost} at the beginning of each function
and initialize its value to be 0. 
We will add the value of \texttt{local\_cost} to \texttt{cost} before 
each function return.
After that, we only need to consider where to update \texttt{local\_cost} 
within a function.
We design and implement intra-procedural 
control flow analysis to achieve this.   
Since the algorithm is design to count events on edge,
we split each basic block into two and attribute event number to be 1 
for the edge connecting the two split basic block.  
We attribute event number to be 0 for edges originally in the control flow graphs. 
We calculate spanning tree for the new control flow graphs. 
Edges not in the spanning tree are called chords.
Finally, we applied the depth-first search algorithm proposed in~cite{} to decide
on which chords we should increment 
\texttt{local\_cost} and how much values we should add to \texttt{local\_cost}.
 

The second optimization targets improving the performance of hash-table lookup.
For each read and write on memory cell w, 
aprof needs to query a hash-table for the latest access time for w and decide 
whether RMS should be updated.
Aprof also needs to update the hash-table entry for w when necessary. 

Instead of using hash-table, we use a page-table to contain timestamp information. 
We declare timestamp as \texttt{long} integer. 
To balance runtime overhead and memory overhead, 
we design a 4-layer page table for 32-bit program 
and 6-layer page table for 64-bit program.
We use 4kb consecutive memory space to hold pointers to next layer 
or timestamps for memory cell. 
Compared with hash-table, page-page considers data locality and can lead 
to a better cache performance. 
To further improve performance, 
we add an extra variable to hold a pointer pointing 
to the last referred memory space holding timestamp.
When new query coming, we first check the saved pointer value can be used, if not,
we will conduct page-table look up.  

The third optimization tries to reduce the number of instrumentation for read and write. 
For this optimization, we only focus on stack memory cells holding 
scalar variables and only used as parameters for read and write.  
We add these conditions, because we want to avoid complex pointer alias analysis, 
which is highly possible to introduce inaccurate results. 
For read conducted on these memory cells, 
if it is dominated by another read or write on the same memory cell, we skip instrumenting this read.
For a write conducted on one of these memory cells, 
if it is dominated by another write on the the same cell, we skip instrumenting this write. 
{\bf xx: providing more explannation here}




\subsection{Enhancing RMS}
There are two limitations in applying RMS. 
In this section, we will discuss how to augment 
RMS to address these two limitations.

{\bf xxx: there is the problem for recursive functions, using GCC#27733 as example}






\begin{figure}
\centering
\lstset{basicstyle=\ttfamily\fontsize{7}{8}\selectfont,
     morekeywords={+},keepspaces=true,numbers=left}
  \mbox{\lstinputlisting[mathescape,boxpos=t]{figure/apache34464.c}}
\caption{An Apache performance problem in $O(N^2)$ complexity. 
(Execution time scales polynomially in the number of characters read from  \texttt{getchar()}.) }
\vspace{-0.05in}
\label{fig:apache34464}
\vspace{-0.05in}
\end{figure}


Another problem for RMS is that it does not consider inputs from I/O.
Buggy code fragment for Apache\#34463 is shown 
in Figure~\ref{fig:apache34464}.
The \texttt{while} loop on line 4 searches a string \texttt{source} for a target sub-string \texttt{target}.
If the \texttt{while} loop cannot find, 
a new character from I/O function \texttt{getchar()} 
on line 6 will be appended to string \texttt{source}, 
and the loop will search string \texttt{source} again from the beginning. 
The input size for this piece of codes depend on how many characters got from \texttt{getchar()}.
Since all memory cells of string \texttt{source} are written 
firstly with characters from \texttt{getchar()} 
by this piece of codes, 
no matter how many characters we get from \texttt{getchar()}, 
the RMS value for this piece of code is constant depending 
on the size of string \texttt{target}, 
variable \texttt{sourceLen} and variable \texttt{targetLen}, 
as shown in Figure~\ref{fig:apache34464-line}.

\subsection{Discussion}

{\bf xxx: top-down view}

{\bf xxx: Here we want accurate results while trading runtime overhead}