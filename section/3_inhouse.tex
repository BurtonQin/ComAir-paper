
\newpage
\section{In-house Algorithmic Profiling}
\label{sec:inhouse}

In this section, we discuss the design and implementation for the in-house version of \Tool.
Under the in-house setting, 
\Tool can help developers conduct algorithmic profiling to detect 
previously unknown complexity problems before releasing their software, 
or help developers diagnose and fix complexity problems reported by end users. 

To conduct algorithmic profiling,
we first need to record \textit{input} size and \textit{cost} for different code constructs 
during multiple executions;
we then plot records from the same code construct with input size as x-axis and cost as y-axis; 
and finally, we infer a cost function of the input size.
The code constructs could be loops and functions. 
In order to design \Tool, 
there are three fundamental questions we need to answer:
1) how to design input metric; 2) how to design cost metric; 
and 3) how to infer and compare cost functions.


\subsection{Input Metric Design}
\label{sec:input}

The goal of input metric design is to figure out general metrics, 
which can represent input sizes for different code constructs. 
We cannot rely on developers to manually label or specify input information 
for different code constructs, 
because it is time-consuming and also difficult for complex code constructs.  
There are several metrics, which can be used to measure input for a code construct.
We discuss commonly used ones as follows. 

\subsubsection{Program input}
As discussed in Section~\ref{sec:process}, 
users tend to specify how to change the whole program 
input to describe the perceived complexity problem.
It is fairly easy to measure the input size for the whole program based on users' reports.
One way to measure the input size for a code construct inside a program
is to simply use the input size of the whole program. 
However, the whole program input 
is related to the input of a code construct in various ways.
Changing the whole program input may not change input sizes for 
all code constructs. 
Using the input size of the whole program as an input metric for a code 
construct may lead to incorrect profiling results. 

\subsubsection{Read memory size (RMS)}
RMS is proposed as an input size metric for one 
execution of a code construct~\cite{Aprof1,Aprof2}. 
RMS is defined as the number of distinct memory cells 
whose first access is read. 
RMS considers both read accesses conducted by a code construct directly 
and read accesses conducted by 
functions called from the code construct. 
RMS is a generic metric for input size, 
and it can provide important input information for many complexity problems.   
Given a code construct \texttt{c}, which is inside a loop \texttt{l} and executed
$n$ times in one single run, 
we would have $n$ RMS records for \texttt{c}. 
There are two methods to analyze these $n$ RMS records.

\begin{itemize}

\item First, \textit{top-down} method. 
When analyzing complexity for \texttt{c}, 
we consider the $n$ records independently from each other~\cite{Aprof1,Aprof2}. 
The effect of multiple executions of \texttt{c} 
will be aggregated when analyzing complexity for \texttt{l}.

\item Second, \textit{bottom-up} method. 
When analyzing complexity for \texttt{c}, 
we merge the $n$ records and calculate the number of distinct memory cells 
contributing RMS as the input size of \texttt{c} in the program run.

\end{itemize}



\begin{figure*}
\centering
\subfloat[XXXX]{\includegraphics[width=0.22\linewidth]{figure/mysql27287-complexity-n-square}\label{fig:mysql27287-indep}} 
\subfloat[XXXX]{\includegraphics[width=0.22\linewidth]{figure/mysql27287-complexity-n-square}\label{fig:mysql27287-outer}}
\subfloat[XXXX]{\includegraphics[width=0.22\linewidth]{figure/gcc27733-time-cost-line}\label{fig:mysql27287-merge}} 
\subfloat[XXXX]{\includegraphics[width=0.22\linewidth]{figure/gcc27733-time-cost-line}\label{fig:mysql27287-inner-array}} \\ 
\vspace{-0.1in}
\caption{XXXX
\footnotesize{(These figures show how execution time change with the change of input size for MySQL\#27287, 
 Apache\#34464, Mozilla\#477564, and GCC\#27733. For each complexity problem, we use 10 distinct inputs.)}} 
\label{fig:time} 
\end{figure*} 

Take MySQL\#27287 as an example.
RMS for one single execution of
the buggy loop in Figure~\ref{fig:mysql27287}
is roughly equal to 2 times the number of \texttt{XML\_NODE} 
accessed during the execution, 
because the \texttt{level} field and the \texttt{type} field of 
different \texttt{XML\_NODE}s are read in different loop iterations.
Although variable \texttt{p} and \texttt{level} are also read in each iteration,
RMS only considers distinct memory cells and 
only increments its value for the first read on these two variables in the first iteration. 
The outer loop, not shown in Figure~\ref{fig:mysql27287}, 
invokes function \texttt{xml\_parent\_tag} for every \texttt{XML\_NODE} contained
in the same array \texttt{items}.
If we use the top-down method to analyze the buggy loop
(or function \texttt{xml\_parent\_tag}), 
execution cost is in linear relationship with RMS, 
as shown in Figure~\ref{fig:mysql27287-indep}.
The $O(N^2)$ complexity can be inferred from the side of the outer loop, 
as shown in Figure~\ref{fig:mysql27287-outer}. 
If we use the bottom-up method, 
we can observe aggregated cost scales 
polynomially in terms of RMS for the buggy loop 
(or function \texttt{xml\_parent\_tag}), 
which is shown in Figure~\ref{fig:mysql27287-merge}. 


Both of the two methods can infer the same complexity, such as for MySQL\#27287,
but they require different implementations.
If we want to apply the bottom-up method to analyze a code construct,
we need to track distinct memory cells contributing RMS for the code construct.
During in-house testing, developers usually want to conduct algorithmic profiling 
for all executed code constructs. 
Tracking memory cells for every code construct will 
incur a very large memory overhead.  
As we will discuss later, to infer complexity in the top-down way 
is not suitable in production runs. 
Therefore, for in-house setting, we will the top-down method, 
while we will use the bottom-up under production-run setting. 

Since RMS considers memory accesses conducted by callees 
and we take a top-down method for in-house setting,
when a monitored program conducts a memory access,
we need to check functions active on the call stack and 
update information necessary to calculate RMS. 
For simplicity, we use function as granularity for code constructs under in-house setting.
Otherwise, we need to check whether a monitored code construct enclose related call sites, 
when we check functions active on the call stack.  

\citet{Aprof1,Aprof2} designed an algorithm to collect 
RMS for all executed functions based on 
Valgrind. We briefly discuss this algorithm firstly, 
and then we will discuss our designed optimizations. 
To count RMS for each function call instance, 
several global variables are maintained: 
\texttt{count}, serving as the current timestamp and incremented 
by 1 after each function invocation,  
\texttt{ts}, a hash table containing the latest access timestamp for each memory cell, 
and \texttt{S}, a shadow stack tracking all active functions on the stack. 
Four hook functions are instrumented for four types of instructions:
\texttt{call}, \texttt{return}, \texttt{read}, and \texttt{write}.
The \texttt{call} hook function will increment the timestamp variable \texttt{count} 
and grow the shadow stack \texttt{S}.
The \texttt{return} hook function will generate a log containing the returning function's RMS.
The \texttt{read} hook function will query the hash table \texttt{ts} to decide whether 
to increment RMS for all the functions active on the shadow stack \texttt{S}.
Both the \texttt{read} and \texttt{write} hook functions will update the hash table \texttt{ts}
by using the value of \texttt{count} to maintain 
the latest access timestamp for each memory cell. 

We design three optimizations to reduce the runtime overhead when collecting RMS
from two aspects:
we try to reduce the number of instrumentation sites, 
and we try to accelerate hook functions. 

{\underline{\textit{Optimization 1}}
The first optimization is an attempt to improve the performance of 
lookups in the hash table \texttt{ts}, 
containing the latest access timestamp for each memory cell.
For a memory read, 
we need to query \texttt{ts} and decide 
whether RMS should be incremented.
For both memory read and write, 
we need to update \texttt{ts} by using the current timestamp \texttt{count}
for accessed memory cells. 

Instead of using a hash table, 
we use a page table to contain the timestamp information. 
To balance runtime overhead and memory overhead, 
we design a four-layer page table for 32-bit programs.
We use 4-KB consecutive memory areas to hold pointers pointing to 
memory areas in the next layer 
or memory areas holding timestamps for memory cells. 
For a monitored 32-bit program, 
we need to calculate four addresses using bitwise operations 
and use the four addresses to refer to each layer of the page table.  
For 64-bit programs, we use six layers.  
Compared with the hash table, 
the page table leverages the locality of memory accesses 
and can lead 
to a better cache performance. 
To further improve performance, 
we add an extra variable to hold the pointer pointing 
to the last referenced memory area holding timestamp.
For each memory read or write, 
we first check whether the saved pointer value can be used. 
We only conduct a page table lookup when the saved value cannot be used. 

{\underline{\textit{Optimization 2}}
The second optimization targets reducing the number of instrumentation sites 
for \texttt{read} and \texttt{write} instructions. 
The \texttt{read} hook function needs to query hashmap \texttt{ts} 
to get the timestamp for the latest access and update RMS value when necessary. 
Both \texttt{read} and \texttt{write} hook functions 
need to use the value of \texttt{count} to update hashmap \texttt{ts}.
As we discussed earlier, the value of texttt{count} will be incremented after each function invocation. 
Therefore, given two consecutive memory accesses on the same memory cell,
if there is no function calls between these two accesses, 
we do not need to instrument the second memory access. 

We rely on dominance analysis to implement this optimization. 
We focus on stack memory cells that hold 
scalar variables and only have \texttt{read} and \texttt{write} as uses 
(i.e., not having ``address of'' as uses).
We only focus on these memory cells,
because we want to avoid pointer alias analysis, 
which may potentially introduce inaccurate results. 
For a \texttt{read} or \texttt{write} instruction on one of these memory cells,
if it is dominated by another \texttt{read} or \texttt{write} instruction, 
and there is not function call on any path between these two instructions,
we will skip to instrument the second instruction.  



\subsection{Cost Design}

\subsubsection{Executed basic blocks (BBs)}
The number of executed BBs for a dynamic instance of a code construct
can be used to measure the execution cost for the dynamic instance. 
A naive method to collect this metric is to add a global counter 
to the monitored program and increase the counter value by 1 inside each BB.  
When entering and leaving a monitored code construct, 
the value of the counter will be dumped to log.

To efficiently count executed BBs, 
we apply an algorithm, which was originally designed to 
efficiently count edge events through selectively instrumenting a counter 
on CFG~\cite{event-counting}.
The algorithm has already been proved to be able to 
conduct path profiling efficiently~\cite{peter-ase,path-profiling}. 

To apply the algorithm,
we instrument a local counter \texttt{local\_cost} for each function
and initialize its value to be 0 at the entry BB. 
We will add the value of \texttt{local\_cost} to a global counter \texttt{cost} 
at the exit BB.
After that, we only need to consider where 
and how to update \texttt{local\_cost} 
within a single function.
We design and implement an intro-procedural control flow analysis
to achieve this.
Given a single function,
we add a fake edge from the exit BB to the entry BB 
to make its CFG strongly connected. 
Since the original algorithm is design to count edge events,
we split each BB into two 
and label the event number to be 1 for each edge connecting a pair of split BBs 
We label the event number to be 0 for all other edges.
We compute a spanning tree~\cite{spanning} for the new CFG.
Edges not in the spanning tree are called chords.
We apply the depth-first search algorithm proposed in~\cite{event-counting} 
to calculate on which chords we should change 
\texttt{local\_cost} 
and how much we should change.

If a monitored code construct is not a function,
We need to figure out the accurate value for the global counter \texttt{cost} 
before dumping its value 
at the first and last BB of the monitored code construct.
The algorithm we apply is also discussed in~\cite{event-counting}.




\input{section/tab_inhouse1}
\input{section/tab_inhouse2}